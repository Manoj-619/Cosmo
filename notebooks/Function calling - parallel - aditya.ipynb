{
 "cells": [
  {
   "cell_type": "raw",
   "id": "95bd1ed4-14fc-4f26-9c06-e81a5056e58c",
   "metadata": {},
   "source": [
    "import os\n",
    "git_dir = os.path.dirname(os.getcwd())\n",
    "project_dir = os.path.join(git_dir,'zavmo')\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b94438-76fd-49e7-839f-06f1541c1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8a67799a-bc6a-4a7a-9bbd-ac0c94394504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from helpers.chat import get_openai_completion,make_function_call,get_prompt, make_structured_call\n",
    "from helpers.functions import parse_type\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "17295ca8-378f-479d-ba20-4f04ea99f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, create_model, Field\n",
    "from typing import get_type_hints, Annotated, Union, List, Optional\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "893651f3-c548-4dd6-a9d8-7c7f3e7df3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profile(BaseModel):\n",
    "    first_name: str = Field(description=\"The first name of the user, often used to address them directly, e.g., 'Diana' or 'John'.\")\n",
    "    #last_name: str = Field(title=\"Last Name\", description=\"Last name of the user\")\n",
    "    #age: int = Field(..., title=\"Age\", description=\"The age of the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c15dab47-a09f-4efa-8916-346a5930589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg  = {\"role\":\"system\",\"content\":\"Extract information from the text.\"}\n",
    "user_msg    = {\"role\":\"user\",\"content\":\"My name is Aditya Chhabra, and I'm about to turn 29.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5b9344ae-a484-465b-9a59-1dcab95d3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_fields = [\n",
    "    {\n",
    "        'title':'first_name',\n",
    "        'annotation': 'str',\n",
    "        'description': \"The first name of the user, often used to address them directly, e.g., 'Diana' or 'John'.\",\n",
    "        \"examples\": ['John', 'Aditya', 'Mumtaz']\n",
    "    },\n",
    "    {\n",
    "        'title':'last_name',\n",
    "        'annotation': 'str',\n",
    "        'description': \"Last name of the user\",\n",
    "        \"examples\": ['Smith', 'J']\n",
    "    },\n",
    "    {\n",
    "        'title':'age',\n",
    "        'annotation': 'int',\n",
    "        'description': \"The age of the user.\",\n",
    "        \"examples\": [21,30,50]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Dynamically creating fields for the model using Annotated and Field\n",
    "model_fields = {}\n",
    "for field_data in profile_fields:\n",
    "    field_name = field_data['title']\n",
    "    annotation_str   = field_data['annotation']\n",
    "    field_annotation = parse_type(annotation_str)  # Parse the annotation string into a Python annotation    \n",
    "    field  = Field(**field_params)\n",
    "    model_fields[field_name] = Annotated[field_annotation, field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e2fea2fc-b980-48f6-b018-1924518f469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\"Profile\", **model_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e82d5f3a-13c9-4680-9cd0-d5b2348f5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [openai.pydantic_function_tool(model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a6ff72c1-84a3-47f8-93d8-1bc4f9054cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[system_msg, user_msg],\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\",\n",
    "    parallel_tool_calls=True,\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "11011bc6-9452-44e8-91e5-f35b316e559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "80ebf55f-ddd5-45f8-8094-7ebb903fd2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function(arguments='{\"first_name\": \"Aditya\", \"last_name\": \"Chhabra\", \"age\": 29}', name='Profile')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls[0].function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66263f4c-69f6-44a6-864a-875358588a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad8720-4878-4452-b0d3-03bf325ef651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07733bfa-1ffe-4ea9-a5b5-5e14bb2c50e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836752d-47dc-4e38-96e1-5b04be5da138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19824a-6013-44ad-bb21-214293b3642b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f945b-4552-4468-b5e0-45bd526dd418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77dab2-8233-4da0-bff2-38983066353b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81581800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tool_calls(messages, tools, model=\"gpt-4o-mini\", **kwargs):\n",
    "    \"\"\"Completes the chat given a list of messages.\n",
    "            \n",
    "    Args:\n",
    "        messages (list): list of messages to complete the chat with\n",
    "        **kwargs: additional arguments to pass to the OpenAI API, such as\n",
    "            temperature, max_tokens, etc.\n",
    "    Returns:\n",
    "        str: the chat completion\n",
    "    \"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        parallel_tool_calls=True,\n",
    "        **kwargs,\n",
    "    )        \n",
    "    return response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b9e6c-52c5-468c-acf2-ea7cbc2d3304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e29a8-7432-4f94-a7f9-4e1a74bafabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ceffe-da5f-4b6f-accd-8111e8a21e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f364df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor Bot Logic\n",
    "class ExtractorBot:\n",
    "    def __init__(self):\n",
    "        self.profile_data = {}\n",
    "        self.required_fields = [\"first_name\", \"last_name\", \"current_role\", \"learning_interests\"]\n",
    "        self.completed_fields = []\n",
    "        self.tools = [openai.pydantic_function_tool(i) for i in [GetFirstName, GetLastName, GetCurrentRole, GetLearningInterests]]\n",
    "\n",
    "    def extract_data(self, messages):\n",
    "        # Prepare and send messages for tool calls\n",
    "        tool_sys_msg = get_prompt('extractor.md', 'assets/prompts/profile').format(\n",
    "            required_fields=\", \".join(self.required_fields) if self.required_fields else \"No pending fields to extract\"\n",
    "        )\n",
    "        tool_messages = [{\"role\": \"system\", \"content\": tool_sys_msg}] + messages[1:]\n",
    "        tool_calls = make_tool_calls(tool_messages, self.tools)\n",
    "\n",
    "        if tool_calls:\n",
    "            for tool_response in tool_calls:\n",
    "                arg = tool_response.function.arguments\n",
    "                self.profile_data.update(json.loads(arg))\n",
    "\n",
    "            # Update fields status\n",
    "            self.completed_fields = list(set(self.profile_data))\n",
    "            self.required_fields = [field for field in self.required_fields if field not in self.completed_fields]\n",
    "\n",
    "    def are_all_fields_collected(self):\n",
    "        return not self.required_fields\n",
    "\n",
    "    def get_confirmation(self, messages):\n",
    "        answer = make_structured_call(GetConfirmation, messages).answer\n",
    "        return 'Yes' if answer and answer.value == 'Yes' else 'No'\n",
    "\n",
    "\n",
    "# Guiding Bot Logic\n",
    "class ProfileCollector:\n",
    "    def __init__(self, extractor_bot):\n",
    "        self.extractor_bot = extractor_bot\n",
    "        self.history = []\n",
    "        self.confirmed = \"No\"\n",
    "\n",
    "    def system_message(self):\n",
    "        prompt = get_prompt(\"system.md\", \"assets/prompts/profile\")\n",
    "        if self.extractor_bot.are_all_fields_collected():\n",
    "            prompt += \"\\nAsk for confirmation (Yes/No) sharing details\" + f\"\\n\\n```json\\n{json.dumps(self.extractor_bot.profile_data, indent=4)}\\n```\"\n",
    "        return {\"role\": \"system\", \"content\": prompt}\n",
    "\n",
    "    def user_message(self, input=\"\"):\n",
    "        # Generate user message with current field statuses\n",
    "        completed = \", \".join(self.extractor_bot.completed_fields) or \"Not completed any field yet.\"\n",
    "        required = \", \".join(self.extractor_bot.required_fields) or \"Received information for all remaining fields.\"\n",
    "        content = f\"Field Extraction Information\\n\\nCompleted Fields:\\n{completed}\\n\\nRequired Fields:\\n{required}\\n\\nUser response:\\n{input}\"\n",
    "        self.user_mssg = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "    def ask_question(self):\n",
    "        # Check if all fields are collected and ask for confirmation if needed\n",
    "        try: \n",
    "            self.user_mssg\n",
    "        except:\n",
    "            self.user_message()\n",
    "\n",
    "        if self.extractor_bot.are_all_fields_collected():\n",
    "            user_mssg = self.user_mssg \n",
    "            user_mssg['content'] = user_mssg['content'] + \"\\n\\nIf updates on any field is required and user will mention corresponding to what is asked, or if user says No. Take it as a No\"\n",
    "            messages = [self.system_message()] + self.history + [user_mssg]\n",
    "            confirmation = self.extractor_bot.get_confirmation(messages)\n",
    "            \n",
    "            if confirmation == \"Yes\":\n",
    "                self.confirmed = \"Yes\"\n",
    "                return self.summarize_profile()\n",
    "\n",
    "        # Collect remaining fields or reattempt extraction if confirmation is \"No\"\n",
    "        if not self.extractor_bot.are_all_fields_collected() or self.confirmed != \"Yes\":\n",
    "            tool_messages = self.history + [self.user_mssg]\n",
    "            self.extractor_bot.extract_data(tool_messages)\n",
    "\n",
    "            # Generate and return assistant message\n",
    "            messages = [self.system_message()] + self.history + [self.user_mssg]\n",
    "            assistant_message = get_openai_completion(messages)\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "            self.history = messages[1:]  # Update history\n",
    "            return assistant_message\n",
    "\n",
    "    def summarize_profile(self):\n",
    "        return f\"Great! Your profile is complete:\\n\\n```json\\n{json.dumps(self.extractor_bot.profile_data, indent=4)}\\n```\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc80ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_bot = ExtractorBot()\n",
    "pc            = ProfileCollector(extractor_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b91221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thank you for sharing, Mumtaz! 🎉 I've noted down your first name and current role. \n",
       "\n",
       "Could you please tell me your last name? 😊"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(pc.ask_question())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc39075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.user_message(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43fe24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.user_message(\"Mumtaz Rahmani, current role is Junior software engineer, learning interests are invloved around LLMs and stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad6b93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Mumtaz',\n",
       " 'last_name': 'Rahmani',\n",
       " 'current_role': 'Junior software engineer',\n",
       " 'learning_interests': ['LLMs', 'stats']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.extractor_bot.profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8f15c6a-dc3f-4039-a688-e9b0fb105bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pc.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07dc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tool_sys_mssg = get_prompt('extractor.md','assets/prompts/profile').format(required_fields=\", \".join(pc.extractor_bot.required_fields) if pc.extractor_bot.required_fields else \"No pendig fields to extract\")\n",
    "tool_messages = [{\"role\":\"system\",\"content\":tool_sys_mssg}]\n",
    "tool_messages.extend(messages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\":\"user\",\"content\":\"Yes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad04d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = make_structured_call(GetConfirmation,messages).answer\n",
    "if answer:\n",
    "    print(answer.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c99c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37540403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bb0d623",
   "metadata": {},
   "source": [
    "## Internally sending tool response to model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192abbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03538316",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = get_openai_completion(messages, tools=tools, tool_choice=\"auto\", parallel_tool_calls=True)\n",
    "\n",
    "tool_calls = message.tool_calls\n",
    "if tool_calls:\n",
    "    print(f\"Tools called: {[tool.function.name for tool in tool_calls]}\")\n",
    "    function_call_messages=[message]\n",
    "    for tool in tool_calls:\n",
    "        arguments = tool.function.arguments\n",
    "        function_call_messages.extend([{\"role\": \"tool\", \"content\": json.dumps(arguments), \"tool_call_id\": tool.id}])\n",
    "        profile_data.update(json.loads(arguments))\n",
    "    messages.extend(function_call_messages)\n",
    "    while message.content==None:\n",
    "        message=get_openai_completion(messages, tools=tools, tool_choice=\"auto\", parallel_tool_calls=True)\n",
    "        print(\"Running in while loop\")\n",
    "\n",
    "assistant_response = message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb480a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea72cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\":\"assistant\",\"content\":assistant_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b0adc-83a2-4fdc-a519-cd77caf83412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claude_response(sys_mssg,messages,model=\"claude-3-opus-20240229\"):\n",
    "    client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    message = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        system=sys_mssg,\n",
    "        messages=messages\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "claude_response = get_claude_response(sys_mssg,messages[1:])\n",
    "claude_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d868630-288b-499f-8b0f-9b482ab89000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889243a-f1f0-4094-bc7d-bc65d8854dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22effca4-389b-4cd2-b8b3-d80e3faa8479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
