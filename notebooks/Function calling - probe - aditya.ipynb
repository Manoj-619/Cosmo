{
 "cells": [
  {
   "cell_type": "raw",
   "id": "beee9d4d-e989-446f-93fc-2376647388b5",
   "metadata": {},
   "source": [
    "import os\n",
    "git_dir = os.path.dirname(os.getcwd())\n",
    "project_dir = os.path.join(git_dir,'zavmo')\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b94438-76fd-49e7-839f-06f1541c1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a67799a-bc6a-4a7a-9bbd-ac0c94394504",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_openai_completion, make_function_call, get_prompt, make_structured_call\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Markdown\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helpers'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from helpers.chat import get_openai_completion, make_function_call, get_prompt, make_structured_call\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17295ca8-378f-479d-ba20-4f04ea99f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from helpers.functions import create_pydantic_model, get_fields, parse_type\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1805ea81-da63-457d-b3a5-9ff93b91c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_name = 'profile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cc400a62-aa93-460f-8d0d-cd8bb3f67bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_data = get_fields(f\"{stage_name}/extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "964e2582-86d1-4394-abb7-0ae681a7a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_fields      = get_fields(f\"{stage_name}/probe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b957c163-9fce-49fd-961d-8ac6d70af963",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content = \"\"\"\n",
    "Zavmo: What new information can we extract from the user's response?\n",
    "Learner: My name is Aditya Chhabra and I'm 28 years old.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "744287c4-a8a7-4487-90d1-5fcb3c137f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_pydantic_model(f\"{stage_name}_new_attributes\", \n",
    "                              fields=extraction_data['filter_fields'], \n",
    "                              description=\"New information about a learner that we can extract from a learner's current response. Use 'none' if no new information can be extracted.\"\n",
    "                             )\n",
    "tools = [openai.pydantic_function_tool(model)]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00724203-3d6d-4a4c-8af6-5244859dbb08",
   "metadata": {},
   "source": [
    "model = create_pydantic_model(stage_name, \n",
    "                              fields=extraction_fields, \n",
    "                              description=\"Tools to use to extract information from a learner's responses\"\n",
    "                             )\n",
    "tools = [openai.pydantic_function_tool(model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7001bc77-9cbb-4639-95fb-59142f24269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_system_template = get_prompt(f\"{stage_name}/extract\")\n",
    "extract_system_message = {\"role\":\"system\",\"content\":extract_system_template}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2750ad23-05bb-49b7-be53-d0dab87427b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = {\"role\":\"user\",\"content\":user_content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c407f-e4b6-4c41-ba6c-f712bed55711",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_system_template = get_prompt(f\"{stage_name}/probe\")\n",
    "probe_system_prompt   = probe_system_template.format(EXAMPLES=example_text)\n",
    "probe_system_message  = {\"role\":\"system\",\"content\":probe_system_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb310d-75d2-4ea8-9f7e-2e2e19b96c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05f49170-2e8e-41f9-add2-e6f7486a975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hey there! ðŸŽ‰ I'm so excited to start this learning adventure with you! Before we dive in, I'd love to get to know you better. This will help me tailor our experience to fit your interests and goals. \n",
       "\n",
       "Could you share your name, what you're looking to learn about, and any preferences you have for our sessions? For example, do you prefer more visual explanations, hands-on activities, or straightforward discussions? ðŸŒŸ "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11011bc6-9452-44e8-91e5-f35b316e559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebf55f-ddd5-45f8-8094-7ebb903fd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.parse_raw(tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor Bot Logic\n",
    "class ExtractorBot:\n",
    "    def __init__(self):\n",
    "        self.profile_data = {}\n",
    "        self.required_fields = [\"first_name\", \"last_name\", \"current_role\", \"learning_interests\"]\n",
    "        self.completed_fields = []\n",
    "        self.tools = [openai.pydantic_function_tool(i) for i in [GetFirstName, GetLastName, GetCurrentRole, GetLearningInterests]]\n",
    "\n",
    "    def extract_data(self, messages):\n",
    "        # Prepare and send messages for tool calls\n",
    "        tool_sys_msg = get_prompt('extractor.md', 'assets/prompts/profile').format(\n",
    "            required_fields=\", \".join(self.required_fields) if self.required_fields else \"No pending fields to extract\"\n",
    "        )\n",
    "        tool_messages = [{\"role\": \"system\", \"content\": tool_sys_msg}] + messages[1:]\n",
    "        tool_calls = make_tool_calls(tool_messages, self.tools)\n",
    "\n",
    "        if tool_calls:\n",
    "            for tool_response in tool_calls:\n",
    "                arg = tool_response.function.arguments\n",
    "                self.profile_data.update(json.loads(arg))\n",
    "\n",
    "            # Update fields status\n",
    "            self.completed_fields = list(set(self.profile_data))\n",
    "            self.required_fields = [field for field in self.required_fields if field not in self.completed_fields]\n",
    "\n",
    "    def are_all_fields_collected(self):\n",
    "        return not self.required_fields\n",
    "\n",
    "    def get_confirmation(self, messages):\n",
    "        answer = make_structured_call(GetConfirmation, messages).answer\n",
    "        return 'Yes' if answer and answer.value == 'Yes' else 'No'\n",
    "\n",
    "\n",
    "# Guiding Bot Logic\n",
    "class ProfileCollector:\n",
    "    def __init__(self, extractor_bot):\n",
    "        self.extractor_bot = extractor_bot\n",
    "        self.history = []\n",
    "        self.confirmed = \"No\"\n",
    "\n",
    "    def system_message(self):\n",
    "        prompt = get_prompt(\"system.md\", \"assets/prompts/profile\")\n",
    "        if self.extractor_bot.are_all_fields_collected():\n",
    "            prompt += \"\\nAsk for confirmation (Yes/No) sharing details\" + f\"\\n\\n```json\\n{json.dumps(self.extractor_bot.profile_data, indent=4)}\\n```\"\n",
    "        return {\"role\": \"system\", \"content\": prompt}\n",
    "\n",
    "    def user_message(self, input=\"\"):\n",
    "        # Generate user message with current field statuses\n",
    "        completed = \", \".join(self.extractor_bot.completed_fields) or \"Not completed any field yet.\"\n",
    "        required = \", \".join(self.extractor_bot.required_fields) or \"Received information for all remaining fields.\"\n",
    "        content = f\"Field Extraction Information\\n\\nCompleted Fields:\\n{completed}\\n\\nRequired Fields:\\n{required}\\n\\nUser response:\\n{input}\"\n",
    "        self.user_mssg = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "    def ask_question(self):\n",
    "        # Check if all fields are collected and ask for confirmation if needed\n",
    "        try: \n",
    "            self.user_mssg\n",
    "        except:\n",
    "            self.user_message()\n",
    "\n",
    "        if self.extractor_bot.are_all_fields_collected():\n",
    "            user_mssg = self.user_mssg \n",
    "            user_mssg['content'] = user_mssg['content'] + \"\\n\\nIf updates on any field is required and user will mention corresponding to what is asked, or if user says No. Take it as a No\"\n",
    "            messages = [self.system_message()] + self.history + [user_mssg]\n",
    "            confirmation = self.extractor_bot.get_confirmation(messages)\n",
    "            \n",
    "            if confirmation == \"Yes\":\n",
    "                self.confirmed = \"Yes\"\n",
    "                return self.summarize_profile()\n",
    "\n",
    "        # Collect remaining fields or reattempt extraction if confirmation is \"No\"\n",
    "        if not self.extractor_bot.are_all_fields_collected() or self.confirmed != \"Yes\":\n",
    "            tool_messages = self.history + [self.user_mssg]\n",
    "            self.extractor_bot.extract_data(tool_messages)\n",
    "\n",
    "            # Generate and return assistant message\n",
    "            messages = [self.system_message()] + self.history + [self.user_mssg]\n",
    "            assistant_message = get_openai_completion(messages)\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "            self.history = messages[1:]  # Update history\n",
    "            return assistant_message\n",
    "\n",
    "    def summarize_profile(self):\n",
    "        return f\"Great! Your profile is complete:\\n\\n```json\\n{json.dumps(self.extractor_bot.profile_data, indent=4)}\\n```\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_bot = ExtractorBot()\n",
    "pc            = ProfileCollector(extractor_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(pc.ask_question())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.user_message(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.user_message(\"Mumtaz Rahmani, current role is Junior software engineer, learning interests are invloved around LLMs and stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.extractor_bot.profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f15c6a-dc3f-4039-a688-e9b0fb105bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pc.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07dc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_sys_mssg = get_prompt('extractor.md','assets/prompts/profile').format(required_fields=\", \".join(pc.extractor_bot.required_fields) if pc.extractor_bot.required_fields else \"No pendig fields to extract\")\n",
    "tool_messages = [{\"role\":\"system\",\"content\":tool_sys_mssg}]\n",
    "tool_messages.extend(messages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\":\"user\",\"content\":\"Yes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad04d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = make_structured_call(GetConfirmation,messages).answer\n",
    "if answer:\n",
    "    print(answer.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c99c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37540403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bb0d623",
   "metadata": {},
   "source": [
    "## Internally sending tool response to model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192abbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03538316",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = get_openai_completion(messages, tools=tools, tool_choice=\"auto\", parallel_tool_calls=True)\n",
    "\n",
    "tool_calls = message.tool_calls\n",
    "if tool_calls:\n",
    "    print(f\"Tools called: {[tool.function.name for tool in tool_calls]}\")\n",
    "    function_call_messages=[message]\n",
    "    for tool in tool_calls:\n",
    "        arguments = tool.function.arguments\n",
    "        function_call_messages.extend([{\"role\": \"tool\", \"content\": json.dumps(arguments), \"tool_call_id\": tool.id}])\n",
    "        profile_data.update(json.loads(arguments))\n",
    "    messages.extend(function_call_messages)\n",
    "    while message.content==None:\n",
    "        message=get_openai_completion(messages, tools=tools, tool_choice=\"auto\", parallel_tool_calls=True)\n",
    "        print(\"Running in while loop\")\n",
    "\n",
    "assistant_response = message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb480a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea72cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\":\"assistant\",\"content\":assistant_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b0adc-83a2-4fdc-a519-cd77caf83412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claude_response(sys_mssg,messages,model=\"claude-3-opus-20240229\"):\n",
    "    client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    message = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        system=sys_mssg,\n",
    "        messages=messages\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "claude_response = get_claude_response(sys_mssg,messages[1:])\n",
    "claude_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d868630-288b-499f-8b0f-9b482ab89000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889243a-f1f0-4094-bc7d-bc65d8854dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22effca4-389b-4cd2-b8b3-d80e3faa8479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
