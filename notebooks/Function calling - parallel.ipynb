{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c689073-23e5-4da0-9909-80d7b76cf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "git_dir = os.path.dirname(os.getcwd())\n",
    "project_dir = os.path.join(git_dir,'zavmo')\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b94438-76fd-49e7-839f-06f1541c1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "8a67799a-bc6a-4a7a-9bbd-ac0c94394504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.chat import get_openai_completion,make_function_call,get_prompt, make_structured_call\n",
    "from helpers.functions import OpenAISchema\n",
    "from IPython.display import Markdown\n",
    "import json\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c321b8-ca60-41df-a1c7-15353eadc67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_openai_completion([{\"role\":\"user\",\"content\":\"Hi\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "8104c8f2-861a-4d64-afdc-3abe3b4ab9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Union, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "class GetFirstName(BaseModel):\n",
    "    \"Return the first name of the user\"\n",
    "    first_name: str = Field(\n",
    "        description=\"The first name of the user, often used to address them directly, e.g., 'Diana' or 'John'.\"\n",
    "    )\n",
    "\n",
    "class GetLastName(BaseModel):\n",
    "    \"Return the user's family name or surname\"\n",
    "    last_name: str = Field(\n",
    "        description=\"The last name (surname) of the user, typically following the first name, e.g., 'Smith' or 'Haddad'.\"\n",
    "    )\n",
    "\n",
    "class GetCurrentRole(BaseModel):\n",
    "    current_role: str = Field(\n",
    "        description=\"The specific job position the person is currently in.\"\n",
    "    )\n",
    "\n",
    "class GetLearningInterests(BaseModel):\n",
    "    \"\"\"Topics or subjects related information shared\"\"\"\n",
    "    learning_interests: List[str] = Field(\n",
    "        description=\"A list of specific topic or subject the user is interested in learning.\"\n",
    "    )\n",
    "\n",
    "class Confirmed(str,Enum):\n",
    "    yes = \"Yes\"\n",
    "    no = \"No\"\n",
    "\n",
    "class GetConfirmation(BaseModel):\n",
    "    \"\"\"Confirmation from user whether the shared info was correct\"\"\"\n",
    "    answer: Optional[Confirmed]\n",
    "\n",
    "tools = [GetFirstName, GetLastName, GetCurrentRole, GetLearningInterests,GetConfirmation]\n",
    "tools = [openai.pydantic_function_tool(i) for i in tools]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01a67062",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "81581800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tool_calls(messages, tools, model=\"gpt-4o-mini\", **kwargs):\n",
    "    \"\"\"Completes the chat given a list of messages.\n",
    "            \n",
    "    Args:\n",
    "        messages (list): list of messages to complete the chat with\n",
    "        **kwargs: additional arguments to pass to the OpenAI API, such as\n",
    "            temperature, max_tokens, etc.\n",
    "    Returns:\n",
    "        str: the chat completion\n",
    "    \"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        parallel_tool_calls=True,\n",
    "        **kwargs,\n",
    "    )        \n",
    "    return response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8cf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "f364df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor Bot Logic\n",
    "class ExtractorBot:\n",
    "    def __init__(self):\n",
    "        self.profile_data = {}\n",
    "        self.required_fields = [\"first_name\", \"last_name\", \"current_role\", \"learning_interests\"]\n",
    "        self.completed_fields = []\n",
    "        self.tools = [openai.pydantic_function_tool(i) for i in [GetFirstName, GetLastName, GetCurrentRole, GetLearningInterests]]\n",
    "\n",
    "    def extract_data(self, messages):\n",
    "        # Prepare and send messages for tool calls\n",
    "        tool_sys_msg = get_prompt('extractor.md', 'assets/prompts/profile').format(\n",
    "            required_fields=\", \".join(self.required_fields) if self.required_fields else \"No pending fields to extract\"\n",
    "        )\n",
    "        tool_messages = [{\"role\": \"system\", \"content\": tool_sys_msg}] + messages[1:]\n",
    "        tool_calls = make_tool_calls(tool_messages, self.tools)\n",
    "\n",
    "        if tool_calls:\n",
    "            for tool_response in tool_calls:\n",
    "                arg = tool_response.function.arguments\n",
    "                self.profile_data.update(json.loads(arg))\n",
    "\n",
    "            # Update fields status\n",
    "            self.completed_fields = list(set(self.profile_data))\n",
    "            self.required_fields = [field for field in self.required_fields if field not in self.completed_fields]\n",
    "\n",
    "    def are_all_fields_collected(self):\n",
    "        return not self.required_fields\n",
    "\n",
    "    def get_confirmation(self, messages):\n",
    "        answer = make_structured_call(GetConfirmation, messages).answer\n",
    "        return 'Yes' if answer and answer.value == 'Yes' else 'No'\n",
    "\n",
    "\n",
    "# Guiding Bot Logic\n",
    "class ProfileCollector:\n",
    "    def __init__(self, extractor_bot):\n",
    "        self.extractor_bot = extractor_bot\n",
    "        self.history = []\n",
    "        self.confirmed = \"No\"\n",
    "\n",
    "    def system_message(self):\n",
    "        prompt = get_prompt(\"system.md\", \"assets/prompts/profile\")\n",
    "        if self.extractor_bot.are_all_fields_collected():\n",
    "            prompt += \"\\nAsk for confirmation (Yes/No) sharing details\" + f\"\\n\\n```json\\n{json.dumps(self.extractor_bot.profile_data, indent=4)}\\n```\"\n",
    "        return {\"role\": \"system\", \"content\": prompt}\n",
    "\n",
    "    def user_message(self, input=\"\"):\n",
    "        # Generate user message with current field statuses\n",
    "        completed = \", \".join(self.extractor_bot.completed_fields) or \"Not completed any field yet.\"\n",
    "        required = \", \".join(self.extractor_bot.required_fields) or \"Received information for all remaining fields.\"\n",
    "        content = f\"Field Extraction Information\\n\\nCompleted Fields:\\n{completed}\\n\\nRequired Fields:\\n{required}\\n\\nUser response:\\n{input}\"\n",
    "        self.user_mssg = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "    def ask_question(self):\n",
    "        # Check if all fields are collected and ask for confirmation if needed\n",
    "        try: \n",
    "            self.user_mssg\n",
    "        except:\n",
    "            self.user_message()\n",
    "\n",
    "        if self.extractor_bot.are_all_fields_collected():\n",
    "            user_mssg = self.user_mssg \n",
    "            user_mssg['content'] = user_mssg['content'] + \"\\n\\nIf updates on any field is required and user will mention corresponding to what is asked, or if user says No. Take it as a No\"\n",
    "            messages = [self.system_message()] + self.history + [user_mssg]\n",
    "            confirmation = self.extractor_bot.get_confirmation(messages)\n",
    "            \n",
    "            if confirmation == \"Yes\":\n",
    "                self.confirmed = \"Yes\"\n",
    "                return self.summarize_profile()\n",
    "\n",
    "        # Collect remaining fields or reattempt extraction if confirmation is \"No\"\n",
    "        if not self.extractor_bot.are_all_fields_collected() or self.confirmed != \"Yes\":\n",
    "            tool_messages = self.history + [self.user_mssg]\n",
    "            self.extractor_bot.extract_data(tool_messages)\n",
    "\n",
    "            # Generate and return assistant message\n",
    "            messages = [self.system_message()] + self.history + [self.user_mssg]\n",
    "            assistant_message = get_openai_completion(messages)\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "            self.history = messages[1:]  # Update history\n",
    "            return assistant_message\n",
    "\n",
    "    def summarize_profile(self):\n",
    "        return f\"Great! Your profile is complete:\\n\\n```json\\n{json.dumps(self.extractor_bot.profile_data, indent=4)}\\n```\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "cc80ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_bot = ExtractorBot()\n",
    "pc            = ProfileCollector(extractor_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "3b91221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Great! Your profile is complete:\n",
       "\n",
       "```json\n",
       "{\n",
       "    \"first_name\": \"Mumtaz\",\n",
       "    \"last_name\": \"\",\n",
       "    \"current_role\": \"\",\n",
       "    \"learning_interests\": []\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(pc.ask_question())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "cc39075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.user_message(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "43fe24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.user_message(\"Mumtaz Rahmani, current role is Junior software engineer, learning interests are invloved around LLMs and stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "fad6b93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Mumtaz',\n",
       " 'last_name': 'R',\n",
       " 'current_role': 'Junior Software Engineer',\n",
       " 'learning_interests': ['LLMs', 'Stats']}"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.extractor_bot.profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a3df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "c07dc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pc.history\n",
    "\n",
    "tool_sys_mssg = get_prompt('extractor.md','assets/prompts/profile').format(required_fields=\", \".join(pc.extractor_bot.required_fields) if pc.extractor_bot.required_fields else \"No pendig fields to extract\")\n",
    "tool_messages = [{\"role\":\"system\",\"content\":tool_sys_mssg}]\n",
    "tool_messages.extend(messages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "3efe6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\":\"user\",\"content\":\"Yes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "5ad04d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "answer = make_structured_call(GetConfirmation,messages).answer\n",
    "if answer:\n",
    "    print(answer.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c99c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37540403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bb0d623",
   "metadata": {},
   "source": [
    "## Internally sending tool response to model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192abbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "03538316",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = get_openai_completion(messages, tools=tools, tool_choice=\"auto\", parallel_tool_calls=True)\n",
    "\n",
    "tool_calls = message.tool_calls\n",
    "if tool_calls:\n",
    "    print(f\"Tools called: {[tool.function.name for tool in tool_calls]}\")\n",
    "    function_call_messages=[message]\n",
    "    for tool in tool_calls:\n",
    "        arguments = tool.function.arguments\n",
    "        function_call_messages.extend([{\"role\": \"tool\", \"content\": json.dumps(arguments), \"tool_call_id\": tool.id}])\n",
    "        profile_data.update(json.loads(arguments))\n",
    "    messages.extend(function_call_messages)\n",
    "    while message.content==None:\n",
    "        message=get_openai_completion(messages, tools=tools, tool_choice=\"auto\", parallel_tool_calls=True)\n",
    "        print(\"Running in while loop\")\n",
    "\n",
    "assistant_response = message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "fb480a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi there! I'm Zavmo, your AI educational companion. 🙌 I'm excited to help personalize your learning experience, and I just need to ask you a few simple questions. Let's get started!\n",
       "\n",
       "What's your first name? 😊"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "eea72cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\":\"assistant\",\"content\":assistant_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "c6e5ba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b0adc-83a2-4fdc-a519-cd77caf83412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claude_response(sys_mssg,messages,model=\"claude-3-opus-20240229\"):\n",
    "    client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    message = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        system=sys_mssg,\n",
    "        messages=messages\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "claude_response = get_claude_response(sys_mssg,messages[1:])\n",
    "claude_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d868630-288b-499f-8b0f-9b482ab89000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889243a-f1f0-4094-bc7d-bc65d8854dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22effca4-389b-4cd2-b8b3-d80e3faa8479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
